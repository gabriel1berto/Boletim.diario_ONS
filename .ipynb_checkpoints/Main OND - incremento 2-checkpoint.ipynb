{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb748e11",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d990181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabelas disponíveis\n",
    "\n",
    "    # BALANÇO DE ENERGIA ACUMULADA DIÁRIA\n",
    "        df_BEA_D\n",
    "\n",
    "    # PRODUÇÃO DE ENERGIA POR TIPO\n",
    "        # Hidráulica\n",
    "        df_prodh_rg - produção diária por região + itaipu\n",
    "        df_poth_rg - potencia diária por região + itaipu\n",
    "        df_prodh_usina - produção e potencia diária por usina + itaipu\n",
    "        # Térmica\n",
    "        df_prodt_rg - produção diária por região\n",
    "        df_pott_rg - potencia diária por região\n",
    "        df_prodt_usina -produção e potencia diária por unidade geradora\n",
    "        # Eólica\n",
    "        # Solar\n",
    "    \n",
    "    # Dados dos reservatórios (incompleto)\n",
    "        df_RES_D\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006ce0e8",
   "metadata": {},
   "source": [
    "Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8ab30f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "import fnmatch\n",
    "import urllib.request\n",
    "import telegram\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605f07a4",
   "metadata": {},
   "source": [
    "Download de tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "33bcf06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghumb\\AppData\\Local\\Temp\\ipykernel_13680\\116627987.py:47: RuntimeWarning: coroutine 'Bot.send_message' was never awaited\n",
      "  bot.send_message(chat_id='SEU_CHAT_ID_AQUI', text=f'Arquivo de {regiao} da data {data} baixado com sucesso')\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\ghumb\\AppData\\Local\\Temp\\ipykernel_13680\\116627987.py:50: RuntimeWarning: coroutine 'Bot.send_message' was never awaited\n",
      "  bot.send_message(chat_id='SEU_CHAT_ID_AQUI', text=f'Arquivo de {regiao} da data {data} não encontrado')\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\ghumb\\AppData\\Local\\Temp\\ipykernel_13680\\116627987.py:60: RuntimeWarning: coroutine 'Bot.send_message' was never awaited\n",
      "  bot.send_message(chat_id='SEU_CHAT_ID_AQUI', text=f'Arquivo de produção {prod_type} da data {data} baixado com sucesso')\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\ghumb\\AppData\\Local\\Temp\\ipykernel_13680\\116627987.py:63: RuntimeWarning: coroutine 'Bot.send_message' was never awaited\n",
      "  bot.send_message(chat_id='SEU_CHAT_ID_AQUI', text=f'Arquivo de produção {prod_type} da data {data} não encontrado')\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\ghumb\\AppData\\Local\\Temp\\ipykernel_13680\\116627987.py:73: RuntimeWarning: coroutine 'Bot.send_message' was never awaited\n",
      "  bot.send_message(chat_id='SEU_CHAT_ID_AQUI', text=f'Arquivo de {regiao} da data {data} baixado com sucesso')\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\ghumb\\AppData\\Local\\Temp\\ipykernel_13680\\116627987.py:76: RuntimeWarning: coroutine 'Bot.send_message' was never awaited\n",
      "  bot.send_message(chat_id='SEU_CHAT_ID_AQUI', text=f'Arquivo de {regiao} da data {data} não encontrado')\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\ghumb\\AppData\\Local\\Temp\\ipykernel_13680\\116627987.py:86: RuntimeWarning: coroutine 'Bot.send_message' was never awaited\n",
      "  bot.send_message(chat_id='SEU_CHAT_ID_AQUI', text=f'Arquivo de {regiao} da data {data} baixado com sucesso')\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\ghumb\\AppData\\Local\\Temp\\ipykernel_13680\\116627987.py:89: RuntimeWarning: coroutine 'Bot.send_message' was never awaited\n",
      "  bot.send_message(chat_id='SEU_CHAT_ID_AQUI', text=f'Arquivo de {regiao} da data {data} não encontrado')\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define o número de dias anteriores para buscar as URLs das regiões\n",
    "num_days =3 \n",
    "\n",
    "# Obtém as datas dos últimos 'num_days' dias e inverte a lista para buscar da menor para a maior data\n",
    "dates = [datetime.today() - timedelta(days=x) for x in range(num_days)][::-1]\n",
    "\n",
    "# Define os formatos das datas para uso na URL e no nome do arquivo\n",
    "date_formats = [date.strftime('%Y_%m_%d') for date in dates]\n",
    "date_formats2 = [date.strftime('%d-%m-%Y') for date in dates]\n",
    "\n",
    "# Define as URLs de download com variação das datas definidas\n",
    "url_regioes = {}\n",
    "url_prod = {}\n",
    "url_reservatorios= {}\n",
    "\n",
    "for i in range(num_days):\n",
    "    # BALANÇO DE ENERGIA ACUMULADA DIÁRIA - BEA\n",
    "    url_regioes[date_formats[i]] = {\n",
    "        'sul': f'https://sdro.ons.org.br/SDRO/DIARIO/{date_formats[i]}/HTML/03_DadosDiariosAcumulados_Regiao_{date_formats2[i]}.xlsx',\n",
    "        'sudeste': f'https://sdro.ons.org.br/SDRO/DIARIO/{date_formats[i]}/HTML/04_DadosDiariosAcumulados_Regiao_{date_formats2[i]}.xlsx',\n",
    "        'nordeste': f'https://sdro.ons.org.br/SDRO/DIARIO/{date_formats[i]}/HTML/05_DadosDiariosAcumulados_Regiao_{date_formats2[i]}.xlsx',\n",
    "        'norte': f'https://sdro.ons.org.br/SDRO/DIARIO/{date_formats[i]}/HTML/06_DadosDiariosAcumulados_Regiao_{date_formats2[i]}.xlsx',\n",
    "        'brasil': f'https://sdro.ons.org.br/SDRO/DIARIO/{date_formats[i]}/HTML/07_DadosDiariosAcumulados_Regiao_{date_formats2[i]}.xlsx'\n",
    "    }\n",
    "    # PRODUÇÃO DE ENERGIA POR TIPO (BDE_D)\n",
    "    url_prod[date_formats[i]] = {\n",
    "        '_H': f'https://sdro.ons.org.br/SDRO/DIARIO/{date_formats[i]}/HTML/08_ProducaoHidraulicaUsina_{date_formats2[i]}.xlsx',\n",
    "        '_T': f'https://sdro.ons.org.br/SDRO/DIARIO/{date_formats[i]}/HTML/09_ProducaoTermicaUsina_{date_formats2[i]}.xlsx'\n",
    "        #'PROD_S':PLATAFORMA QUEBRADA\n",
    "        #'PROD_E': PLATAFORMA QUEBRADA\n",
    "    }\n",
    "    \n",
    "    url_reservatorios[date_formats[i]] = {\n",
    "        'sul': f'https://sdro.ons.org.br/SDRO/DIARIO/{date_formats[i]}/HTML/23_SituacaoPrincipaisReservatorios_Regiao_{date_formats2[i]}.xlsx',\n",
    "        'sudeste': f'https://sdro.ons.org.br/SDRO/DIARIO/{date_formats[i]}/HTML/24_SituacaoPrincipaisReservatorios_Regiao_{date_formats2[i]}.xlsx',\n",
    "        'nordeste': f'https://sdro.ons.org.br/SDRO/DIARIO/{date_formats[i]}/HTML/25_SituacaoPrincipaisReservatorios_Regiao_{date_formats2[i]}.xlsx',\n",
    "        'norte': f'https://sdro.ons.org.br/SDRO/DIARIO/{date_formats[i]}/HTML/26_SituacaoPrincipaisReservatorios_Regiao_{date_formats2[i]}.xlsx'\n",
    "    }\n",
    "    \n",
    "# Percorre URL_regioes para tentar baixar os arquivos\n",
    "for data, urls in url_regioes.items():\n",
    "    for regiao, url in urls.items():\n",
    "        filename = f'BEA_D_{regiao.upper()}_{data}.xlsx'\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, filename)\n",
    "            bot = telegram.Bot(token='SEU_TOKEN_AQUI')\n",
    "            bot.send_message(chat_id='SEU_CHAT_ID_AQUI', text=f'Arquivo de {regiao} da data {data} baixado com sucesso')\n",
    "        except urllib.error.HTTPError:\n",
    "            bot = telegram.Bot(token='SEU_TOKEN_AQUI')\n",
    "            bot.send_message(chat_id='SEU_CHAT_ID_AQUI', text=f'Arquivo de {regiao} da data {data} não encontrado')\n",
    "            continue\n",
    "\n",
    "# Percorre URL_prod para tentar baixar os arquivos\n",
    "for data, urls in url_prod.items():\n",
    "    for prod_type, url in urls.items():\n",
    "        filename = f'BDE_D_PROD_{prod_type}_{data}.xlsx'\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, filename)\n",
    "            bot = telegram.Bot(token='SEU_TOKEN_AQUI')\n",
    "            bot.send_message(chat_id='SEU_CHAT_ID_AQUI', text=f'Arquivo de produção {prod_type} da data {data} baixado com sucesso')\n",
    "        except urllib.error.HTTPError:\n",
    "            bot = telegram.Bot(token='SEU_TOKEN_AQUI')\n",
    "            bot.send_message(chat_id='SEU_CHAT_ID_AQUI', text=f'Arquivo de produção {prod_type} da data {data} não encontrado')\n",
    "            continue\n",
    "    \n",
    "# Percorre URL_regioes para tentar baixar os arquivos\n",
    "for data, urls in url_reservatorios.items():\n",
    "    for reservatorios, url in urls.items():\n",
    "        filename = f'RES_{regiao.upper()}_{data}.xlsx'\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, filename)\n",
    "            bot = telegram.Bot(token='SEU_TOKEN_AQUI')\n",
    "            bot.send_message(chat_id='SEU_CHAT_ID_AQUI', text=f'Arquivo de {regiao} da data {data} baixado com sucesso')\n",
    "        except urllib.error.HTTPError:\n",
    "            bot = telegram.Bot(token='SEU_TOKEN_AQUI')\n",
    "            bot.send_message(chat_id='SEU_CHAT_ID_AQUI', text=f'Arquivo de {regiao} da data {data} não encontrado')\n",
    "            continue\n",
    "\n",
    "# Percorre URL_reservatorios para tentar baixar os arquivos\n",
    "for data, urls in url_reservatorios.items():\n",
    "    for regiao, url in urls.items():\n",
    "        filename = f'RES_D_{regiao.upper()}_{data}.xlsx'\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, filename)\n",
    "            bot = telegram.Bot(token='SEU_TOKEN_AQUI')\n",
    "            bot.send_message(chat_id='SEU_CHAT_ID_AQUI', text=f'Arquivo de {regiao} da data {data} baixado com sucesso')\n",
    "        except urllib.error.HTTPError:\n",
    "            bot = telegram.Bot(token='SEU_TOKEN_AQUI')\n",
    "            bot.send_message(chat_id='SEU_CHAT_ID_AQUI', text=f'Arquivo de {regiao} da data {data} não encontrado')\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa8b044",
   "metadata": {},
   "source": [
    "ETLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ebe08d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL BALANÇO DE ENERGIA ACUMULADA DIÁRIA\n",
    "\n",
    "dfs = []\n",
    "for date in date_formats:\n",
    "    df_date = pd.DataFrame()\n",
    "    for regiao in ['sul','sudeste', 'nordeste', 'norte','brasil']:\n",
    "        prod_regiao = f'BEA_D_{regiao.upper()}_{date}.xlsx'\n",
    "        if os.path.exists(prod_regiao):\n",
    "            df = pd.read_excel(prod_regiao, sheet_name='Plan1')\n",
    "            df['data_captura'] = date\n",
    "            df['regiao'] = regiao\n",
    "            df_date = pd.concat([df_date, df], axis=0)\n",
    "        dfs.append(df_date)\n",
    "        \n",
    "\n",
    "# Concatena e remove col completamente vazias\n",
    "    df_BEA_D = pd.concat(dfs, axis=0).dropna()\n",
    "\n",
    "# Renomeia colunas\n",
    "    df_BEA_D = df_BEA_D.rename(columns={'Unnamed: 0': 'data',\n",
    "                             'Unnamed: 1': 'total',\n",
    "                             'Unnamed: 2': 'hidraulica',\n",
    "                             'Unnamed: 3': 'termica',\n",
    "                             'Unnamed: 4': 'eolica',\n",
    "                             'Unnamed: 5': 'solar',\n",
    "                             'Unnamed: 6': 'intercambio',\n",
    "                             'Unnamed: 7': 'carga'})\n",
    "\n",
    "# Limpando o dataframe\n",
    "    to_remove = ['Dados Diários acumulados', 'Valores - MWmed', 'Subsistema Norte', 'Total', np.nan,'Data', 'Subsistema Sul', 'Subsistema Nordeste', 'Subsistema Sudeste']\n",
    "    df_BEA_D = df_BEA_D[~df_BEA_D['data'].isin(to_remove)]\n",
    "\n",
    "# Remove valores que se repetem em 'data' e 'regiao', incluindo valores vazios\n",
    "    df_BEA_D.drop_duplicates(subset=['data', 'regiao'], inplace=True)\n",
    "\n",
    "#atualizando formato dos dados\n",
    "    df_BEA_D['total'] = pd.to_numeric(df_BEA_D['total'], errors='coerce')\n",
    "    df_BEA_D['hidraulica'] = pd.to_numeric(df_BEA_D['hidraulica'], errors='coerce')\n",
    "    df_BEA_D['termica'] = pd.to_numeric(df_BEA_D['termica'], errors='coerce')\n",
    "    df_BEA_D['eolica'] = pd.to_numeric(df_BEA_D['eolica'], errors='coerce')\n",
    "    df_BEA_D['solar'] = pd.to_numeric(df_BEA_D['solar'], errors='coerce')\n",
    "    df_BEA_D['intercambio'] = pd.to_numeric(df_BEA_D['intercambio'], errors='coerce')\n",
    "    df_BEA_D['carga'] = pd.to_numeric(df_BEA_D['carga'], errors='coerce')\n",
    "    df_BEA_D['data'] = pd.to_datetime(df_BEA_D['data'], format='%d/%m/%Y')\n",
    "    df_BEA_D['data_captura'] = pd.to_datetime(df_BEA_D['data_captura'], format='%Y_%m_%d') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "838dceeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao ler o arquivo BDE_D_PROD__H_2023_03_06.xlsx: type object 'datetime.datetime' has no attribute 'datetime'\n",
      "Erro ao ler o arquivo BDE_D_PROD__H_2023_03_07.xlsx: type object 'datetime.datetime' has no attribute 'datetime'\n",
      "Erro ao ler o arquivo BDE_D_PROD__T_2023_03_06.xlsx: type object 'datetime.datetime' has no attribute 'datetime'\n",
      "Erro ao ler o arquivo BDE_D_PROD__T_2023_03_07.xlsx: type object 'datetime.datetime' has no attribute 'datetime'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13680\\891108714.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;31m# Concatenando os dataframes Hidráulico Térmico\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m \u001b[0mdf_prodh_rg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfs_h1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[0mdf_poth_rg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfs_h2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[0mdf_prodh_usina\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfs_h3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m     \"\"\"\n\u001b[1;32m--> 347\u001b[1;33m     op = _Concatenator(\n\u001b[0m\u001b[0;32m    348\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No objects to concatenate\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# Obtém o caminho atual do diretório do script\n",
    "dir_path = os.getcwd()\n",
    "\n",
    "# Define o padrão de nome de arquivo para correspondência\n",
    "filename_pattern_h = 'BDE_D_PROD__H*.xlsx'\n",
    "filename_pattern_t = 'BDE_D_PROD__T*.xlsx'\n",
    "\n",
    "# Cria listas vazias para armazenar os DataFrames de cada tipo de arquivo\n",
    "dfs_h1 = []\n",
    "dfs_h2 = []\n",
    "dfs_h3 = []\n",
    "dfs_t1 = []\n",
    "dfs_t2 = []\n",
    "dfs_t3 = []\n",
    "\n",
    "# Percorre todos os arquivos na pasta atual que correspondem ao padrão de nome de arquivo\n",
    "for filename in os.listdir(dir_path):\n",
    "    if fnmatch.fnmatch(filename, filename_pattern_h):\n",
    "        try:\n",
    "            # Extrai a data do nome do arquivo\n",
    "            date_str = '_'.join(filename.split('_')[5:9]).split('.')[0]\n",
    "            \n",
    "            # Tenta converter a string em um objeto datetime\n",
    "            try:\n",
    "                date_obj = datetime.datetime.strptime(date_str, '%Y_%m_%d')\n",
    "                \n",
    "                # Lê as tabelas prodh_rg, poth_rg e prodh_usina em seus respectivos dataframes e adiciona uma coluna com a data\n",
    "                prodh_rg = pd.read_excel(os.path.join(dir_path, filename), sheet_name='Plan1', header=3, usecols='A:D', nrows=7)\n",
    "                prodh_rg['data'] = date_obj\n",
    "                dfs_h1.append(prodh_rg)\n",
    "                \n",
    "                poth_rg = pd.read_excel(os.path.join(dir_path, filename), sheet_name='Plan1', header=11, usecols='A:D', nrows=7)\n",
    "                poth_rg['data'] = date_obj\n",
    "                dfs_h2.append(poth_rg)\n",
    "                \n",
    "                prodh_usina = pd.read_excel(os.path.join(dir_path, filename), sheet_name='Plan1', header=22, usecols='A:D', nrows=1000)\n",
    "                prodh_usina['data'] = date_obj\n",
    "                dfs_h3.append(prodh_usina)\n",
    "            except ValueError:\n",
    "                # A string não pode ser convertida em uma data\n",
    "                print(f\"Valor inválido na coluna date do arquivo {filename}: {date_str}\")\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao ler o arquivo {filename}: {e}\")\n",
    "    \n",
    "    elif fnmatch.fnmatch(filename, filename_pattern_t):\n",
    "        try:\n",
    "            # Extrai a data do nome do arquivo\n",
    "            date_str = '_'.join(filename.split('_')[5:9]).split('.')[0]\n",
    "            \n",
    "            # Tenta converter a string em um objeto datetime\n",
    "            try:\n",
    "                date_obj = datetime.datetime.strptime(date_str, '%Y_%m_%d')\n",
    "                \n",
    "                # Lê as tabelas prodt_rg, pott_rg e prodt_usina em seus respectivos dataframes e adiciona uma coluna com a data\n",
    "                prodt_rg = pd.read_excel(os.path.join(dir_path, filename), sheet_name='Plan1', header=3, usecols='A:D', nrows=7)\n",
    "                prodt_rg['data'] = date_obj\n",
    "                dfs_t1.append(prodt_rg)\n",
    "                \n",
    "                pott_rg = pd.read_excel(os.path.join(dir_path, filename), sheet_name='Plan1', header=10, usecols='A:D', nrows=7)\n",
    "                pott_rg['data'] = date_obj\n",
    "                dfs_t2.append(pott_rg)\n",
    "                \n",
    "                prodt_usina = pd.read_excel(os.path.join(dir_path, filename), sheet_name='Plan1', header=20, usecols='A:D', nrows=1000)\n",
    "                prodt_usina['data'] = date_obj\n",
    "                dfs_t3.append(prodh_usina)\n",
    "            except ValueError:\n",
    "                # A string não pode ser convertida em uma data\n",
    "                print(f\"Valor inválido na coluna date do arquivo {filename}: {date_str}\")\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao ler o arquivo {filename}: {e}\")\n",
    "        \n",
    "# OBS: a tabela BDE_D_PROD__H Itaipu é classificada como uma região, criando +1 linha de diferença por tabela à BDE_D_PROD__T \n",
    "\n",
    "# Concatenando os dataframes Hidráulico Térmico\n",
    "df_prodh_rg = pd.concat(dfs_h1)\n",
    "df_poth_rg = pd.concat(dfs_h2)\n",
    "df_prodh_usina = pd.concat(dfs_h3)\n",
    "df_prodt_rg = pd.concat(dfs_t1)\n",
    "df_pott_rg = pd.concat(dfs_t2)\n",
    "df_prodt_usina = pd.concat(dfs_t3)\n",
    "\n",
    "\n",
    "# A tabela df_prodt_rg apresentou valores em object mesmo a leitura correta\n",
    "df_prodt_rg['GWh no Dia'] = pd.to_numeric(df_prodt_rg['GWh no Dia'], errors='coerce')\n",
    "df_prodt_rg['GWh acum. no Mês até o Dia'] = pd.to_numeric(df_prodt_rg['GWh acum. no Mês até o Dia'], errors='coerce')\n",
    "df_prodt_rg['GWh acum. no Ano até o Dia'] = pd.to_numeric(df_prodt_rg['GWh acum. no Ano até o Dia'], errors='coerce')\n",
    "\n",
    "\n",
    "# Removendo linhas duplicadas\n",
    "dfs = [df_prodh_rg, df_poth_rg, df_prodh_usina, df_prodt_rg, df_pott_rg, df_prodt_usina]\n",
    "dfs = list(map(lambda df: df.drop_duplicates(), dfs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0eb7a5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0e61a05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bacia</th>\n",
       "      <th>reservatorio</th>\n",
       "      <th>vol_util_%</th>\n",
       "      <th>afluencia</th>\n",
       "      <th>defluencia</th>\n",
       "      <th>vertida</th>\n",
       "      <th>transferida</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>data_captura</th>\n",
       "      <th>regiao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dados Hidráulicos dos Reservatórios</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023_03_06</td>\n",
       "      <td>sul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023_03_06</td>\n",
       "      <td>sul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023_03_06</td>\n",
       "      <td>sul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subsistema Sul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023_03_06</td>\n",
       "      <td>sul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bacia</td>\n",
       "      <td>Reservatório</td>\n",
       "      <td>Nível-m</td>\n",
       "      <td>Volume Útil-%</td>\n",
       "      <td>Vazão - m³/s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023_03_06</td>\n",
       "      <td>sul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>STO ANTONIO DO JARI</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>203.960007</td>\n",
       "      <td>2867</td>\n",
       "      <td>2867</td>\n",
       "      <td>2063</td>\n",
       "      <td>0</td>\n",
       "      <td>2023_03_07</td>\n",
       "      <td>norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>BELO MONTE</td>\n",
       "      <td>95.760002</td>\n",
       "      <td>45.18</td>\n",
       "      <td>0</td>\n",
       "      <td>8619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023_03_07</td>\n",
       "      <td>norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PIMENTAL</td>\n",
       "      <td>96.93</td>\n",
       "      <td>-13.67</td>\n",
       "      <td>15690.980469</td>\n",
       "      <td>6651</td>\n",
       "      <td>4307</td>\n",
       "      <td>8957.209961</td>\n",
       "      <td>2023_03_07</td>\n",
       "      <td>norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TOCANTINS</td>\n",
       "      <td>ESTREITO</td>\n",
       "      <td>154.429993</td>\n",
       "      <td>65.580002</td>\n",
       "      <td>5012.080078</td>\n",
       "      <td>4223</td>\n",
       "      <td>2884</td>\n",
       "      <td>0</td>\n",
       "      <td>2023_03_07</td>\n",
       "      <td>norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>TUCURUI</td>\n",
       "      <td>73.919998</td>\n",
       "      <td>99.379997</td>\n",
       "      <td>17640.710938</td>\n",
       "      <td>16948</td>\n",
       "      <td>12383</td>\n",
       "      <td>0</td>\n",
       "      <td>2023_03_07</td>\n",
       "      <td>norte</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>382 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  bacia         reservatorio  vol_util_%  \\\n",
       "0   Dados Hidráulicos dos Reservatórios                  NaN         NaN   \n",
       "1                                   NaN                  NaN         NaN   \n",
       "2                                   NaN                  NaN         NaN   \n",
       "3                        Subsistema Sul                  NaN         NaN   \n",
       "4                                 Bacia         Reservatório     Nível-m   \n",
       "..                                  ...                  ...         ...   \n",
       "11                                  NaN  STO ANTONIO DO JARI   30.799999   \n",
       "12                                  NaN           BELO MONTE   95.760002   \n",
       "13                                  NaN             PIMENTAL       96.93   \n",
       "14                            TOCANTINS             ESTREITO  154.429993   \n",
       "15                                  NaN              TUCURUI   73.919998   \n",
       "\n",
       "        afluencia    defluencia vertida transferida   Unnamed: 8 data_captura  \\\n",
       "0             NaN           NaN     NaN         NaN          NaN   2023_03_06   \n",
       "1             NaN           NaN     NaN         NaN          NaN   2023_03_06   \n",
       "2             NaN           NaN     NaN         NaN          NaN   2023_03_06   \n",
       "3             NaN           NaN     NaN         NaN          NaN   2023_03_06   \n",
       "4   Volume Útil-%  Vazão - m³/s     NaN         NaN          NaN   2023_03_06   \n",
       "..            ...           ...     ...         ...          ...          ...   \n",
       "11     203.960007          2867    2867        2063            0   2023_03_07   \n",
       "12          45.18             0    8619           0            0   2023_03_07   \n",
       "13         -13.67  15690.980469    6651        4307  8957.209961   2023_03_07   \n",
       "14      65.580002   5012.080078    4223        2884            0   2023_03_07   \n",
       "15      99.379997  17640.710938   16948       12383            0   2023_03_07   \n",
       "\n",
       "   regiao  \n",
       "0     sul  \n",
       "1     sul  \n",
       "2     sul  \n",
       "3     sul  \n",
       "4     sul  \n",
       "..    ...  \n",
       "11  norte  \n",
       "12  norte  \n",
       "13  norte  \n",
       "14  norte  \n",
       "15  norte  \n",
       "\n",
       "[382 rows x 10 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ELT reservatorios\n",
    "import pandas as pd\n",
    "\n",
    "dfs = []\n",
    "for date in date_formats:\n",
    "    df_date = pd.DataFrame()\n",
    "    for regiao in ['sul','sudeste', 'nordeste', 'norte']:\n",
    "        cap_reservatorio = f'RES_D_{regiao.upper()}_{date}.xlsx'\n",
    "        if os.path.exists(cap_reservatorio):\n",
    "            df = pd.read_excel(cap_reservatorio, sheet_name='Plan1')\n",
    "            filename = os.path.basename(cap_reservatorio)\n",
    "            date_str = '_'.join(filename.split('_')[3:6]).split('.')[0]\n",
    "            df['data_captura'] = date_str\n",
    "            df['regiao'] = regiao\n",
    "            df_date = pd.concat([df_date, df], axis=0)\n",
    "    dfs.append(df_date)\n",
    "\n",
    "# Concatena e remove col completamente vazias\n",
    "df_RES_D = pd.concat(dfs, axis=0)\n",
    "\n",
    "df_RES_D.drop('Unnamed: 2', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Renomeia colunas\n",
    "df_RES_D = df_RES_D.rename(columns={'Unnamed: 0': 'bacia',\n",
    "                             'Unnamed: 1': 'reservatorio',\n",
    "                             'Unnamed: 2': 'nivel_m',\n",
    "                             'Unnamed: 3': 'vol_util_%',\n",
    "                             'Unnamed: 4': 'afluencia',\n",
    "                             'Unnamed: 5': 'defluencia',\n",
    "                             'Unnamed: 6': 'vertida',\n",
    "                             'Unnamed: 7': 'transferida'})\n",
    "\n",
    "# Limpando o dataframe\n",
    "to_remove = ['Dados Hidráulicos dos Reservatórios', 'Subsistema Sul\t', 'Subsistema Norte', 'Bacia', np.nan, 'Subsistema Sul', 'Subsistema Nordeste', 'Subsistema Sudeste']\n",
    "df_BEA_D = df_BEA_D[~df_BEA_D['data'].isin(to_remove)]\n",
    "\n",
    "\n",
    "#atualizando formato dos dados\n",
    "df_BEA_D['total'] = pd.to_numeric(df_BEA_D['total'], errors='coerce')\n",
    "    \n",
    "df_RES_D.dtypes\n",
    "\n",
    "df_RES_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b573a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7918dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4119498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79c46475",
   "metadata": {},
   "source": [
    "Balanço de Energia Acumulado no Mês Até o Dia -https://sdro.ons.org.br/SDRO/DIARIO/2023_03_05/HTML/02_BalancoEnergeticoAcumuloDia_05-03-2023.xlsx\n",
    "\n",
    "Balanço de Energia Diário- https://sdro.ons.org.br/SDRO/DIARIO/2023_03_05/HTML/01_RelBalancoEnergeticoDiario_05-03-2023.xlsx\n",
    "\n",
    "    \n",
    "DADOS ACUMULADO POR REGIÃO \n",
    "            sul - https://sdro.ons.org.br/SDRO/DIARIO/2023_03_05/HTML/03_DadosDiariosAcumulados_Regiao_05-03-2023.xlsx\n",
    "\n",
    "            sudeste - https://sdro.ons.org.br/SDRO/DIARIO/2023_03_05/HTML/04_DadosDiariosAcumulados_Regiao_05-03-2023.xlsx\n",
    "\n",
    "            nordeste - https://sdro.ons.org.br/SDRO/DIARIO/2023_03_05/HTML/05_DadosDiariosAcumulados_Regiao_05-03-2023.xlsx\n",
    "\n",
    "            norte - https://sdro.ons.org.br/SDRO/DIARIO/2023_03_05/HTML/06_DadosDiariosAcumulados_Regiao_05-03-2023.xlsx\n",
    "\n",
    "            sist. interligado nasc - https://sdro.ons.org.br/SDRO/DIARIO/2023_03_05/HTML/07_DadosDiariosAcumulados_Regiao_05-03-2023.xlsx\n",
    "    \n",
    "    \n",
    "PRODUÇÃO\n",
    "\n",
    "            Produção hidraulica por usina - https://sdro.ons.org.br/SDRO/DIARIO/2023_03_05/HTML/08_ProducaoHidraulicaUsina_05-03-2023.xlsx\n",
    "\n",
    "            produção eletrica por usina - https://sdro.ons.org.br/SDRO/DIARIO/2023_03_05/HTML/09_ProducaoTermicaUsina_05-03-2023.xlsx\n",
    "\n",
    "            produção eolica (ta bichado, não libera o pdf no download)\n",
    "\n",
    "            produção solar  (ta bichado, não libera o pdf no download)\n",
    "\n",
    "            motivo do despacho termico - https://sdro.ons.org.br/SDRO/DIARIO/2023_03_05/HTML/12_MotivoDespachoTermico_05-03-2023.xlsx\n",
    "\n",
    "            reserva girante da demanda máxima - https://sdro.ons.org.br/SDRO/DIARIO/2023_03_05/HTML/13_ReservaGiranteDemandaMaxima_05-03-2023.xlsx\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "CARDA HORARIA\n",
    "\n",
    "carga horaria por subsistema - https://sdro.ons.org.br/SDRO/DIARIO/2023_03_05/HTML/14_CargaHorariaSub_05-03-2023.xlsx\n",
    "\n",
    "carga diaria por subsistema - https://sdro.ons.org.br/SDRO/DIARIO/2023_03_05/HTML/15_CargaDiariaSubmercado_05-03-2023.xlsx\n",
    "\n",
    "demanda máxima - https://sdro.ons.org.br/SDRO/DIARIO/2023_03_05/HTML/16_DemandaMaxima_05-03-2023.xlsx\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "Integração de Novos Equipamentos e Linhas de Transmissão no SIN (??)\n",
    "\n",
    "\n",
    "Variação de Energia Armazenada - https://sdro.ons.org.br/SDRO/DIARIO/2023_03_05/HTML/20_VariacaoCargaEnergiaArmazenada_05-03-2023.xlsx\n",
    "\n",
    "Energia natural afluente - https://sdro.ons.org.br/SDRO/DIARIO/2023_03_05/HTML/21_EnergiaNaturalAfluente_05-03-2023.xlsx\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DADOS HIDRAULICOS DOS RESERVATORIOS\n",
    "\n",
    "SUL - https://sdro.ons.org.br/SDRO/DIARIO/2023_03_05/HTML/23_SituacaoPrincipaisReservatorios_Regiao_05-03-2023.xlsx\n",
    "\n",
    "SUDESTE - https://sdro.ons.org.br/SDRO/DIARIO/2023_03_05/HTML/24_SituacaoPrincipaisReservatorios_Regiao_05-03-2023.xlsx\n",
    "\n",
    "NORDESTE - https://sdro.ons.org.br/SDRO/DIARIO/2023_03_05/HTML/25_SituacaoPrincipaisReservatorios_Regiao_05-03-2023.xlsx\n",
    "\n",
    "NORTE - https://sdro.ons.org.br/SDRO/DIARIO/2023_03_05/HTML/26_SituacaoPrincipaisReservatorios_Regiao_05-03-2023.xlsx\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876bed7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
